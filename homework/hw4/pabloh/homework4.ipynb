{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7c25af8",
   "metadata": {},
   "source": [
    "# Homework 4: Information Security\n",
    "\n",
    "### Course: Information Security\n",
    "\n",
    "### **Names**\n",
    "Ericson López\n",
    "\n",
    "Pablo Herrera"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab3ede6",
   "metadata": {},
   "source": [
    "## 1. Foundational Research: Ecuadorian Data Sovereignty (LOPDP)\n",
    "\n",
    "Ecuador’s Ley Orgánica de Protección de Datos Personales (LOPDP), enforced starting in July 2023 , establishes comprehensive individual rights over personal data. This module requires you to research the specific mandates of this law as they relate to automated decision-making and cross-border data management.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0a2f4b",
   "metadata": {},
   "source": [
    "### What are the three core principles (criterios mínimos) that govern all data processing activities under the LOPDP?   \n",
    "\n",
    "Aunque la LOPDP establece una serie principios en su Artículo 10, el texto hace referencia explícita a los \"criterios de legalidad, proporcionalidad y necesidad\" como estándares mínimos que deben cumplirse, especialmente en contextos sensibles o de excepciones (como seguridad del Estado o emergencias sanitarias).\n",
    "\n",
    "Los 3 Principios/Criterios Nucleares:\n",
    "\n",
    "1. Juridicidad (Legalidad): Los datos personales deben tratarse con estricto apego a la Constitución, los instrumentos internacionales y la Ley. Esto implica que todo tratamiento debe tener una base legitimadora clara (como el consentimiento o una obligación legal) y no puede realizarse por medios desleales o ilícitos.\n",
    "\n",
    "2. Proporcionalidad: El tratamiento debe ser adecuado, necesario, oportuno, relevante y no excesivo en relación con las finalidades para las cuales fueron recogidos. Este criterio busca evitar el uso desmedido de datos que no guarden una relación equilibrada con el objetivo perseguido.\n",
    "\n",
    "3. Pertinencia y Minimización (Necesidad): Los datos personales deben limitarse a lo estrictamente necesario para el cumplimiento de la finalidad del tratamiento. Si la finalidad se puede lograr sin ciertos datos, estos no deben ser recolectados ni procesados.\n",
    "\n",
    "Otros principios rectores mencionados en la Ley (Art. 10):\n",
    "- Lealtad \n",
    "- Transparencia \n",
    "- Finalidad \n",
    "- Confidencialidad \n",
    "- Calidad y exactitud \n",
    "- Conservación \n",
    "- Seguridad de datos personales \n",
    "- Responsabilidad proactiva y demostrada \n",
    "- Aplicación favorable al titular \n",
    "- Independencia del control \n",
    "\n",
    "Referencia: Capítulo II (Principios), Artículo 10; y referencias a criterios mínimos en Artículos 2, 7 y 11."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be403877",
   "metadata": {},
   "source": [
    "### Locate the specific article (or section within an article) of the LOPDP that grants the data subject the right “to not be object of a decision based solely on automated valuations”. Explain the details and protections it provides.  \n",
    "\n",
    "Art. 20.- Derecho a no ser objeto de una decisión basada única o parcialmente en valoraciones automatizadas.\n",
    "\n",
    "Este artículo otorga al titular el derecho a no ser sometido a una decisión que se base única o parcialmente en procesos automatizados (incluida la elaboración de perfiles) si esta produce efectos jurídicos en él o atenta contra sus derechos fundamentales.\n",
    "\n",
    "Para garantizar este derecho, la ley faculta al titular a:\n",
    "\n",
    "- Solicitar una explicación motivada sobre la decisión tomada.\n",
    "- Presentar observaciones.\n",
    "- Solicitar los criterios de valoración sobre el programa automatizado.\n",
    "- Solicitar información sobre los tipos de datos utilizados y su fuente.\n",
    "- Impugnar la decisión ante el responsable o encargado.\n",
    "\n",
    "Además, este derecho debe ser informado explícitamente al titular en la primera comunicación.\n",
    "\n",
    "Referencia: Capítulo III (Derechos), Artículo 20."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06266ee6",
   "metadata": {},
   "source": [
    "### In the context of an AI-driven system (e.g., hiring or loan approval), explain the operational impact of this right. How does this LOPDP provision compel a data controller to provide human intervention or oversight?   \n",
    "\n",
    "En el contexto de un sistema impulsado por IA (como aprobación de créditos o contratación), la LOPDP impone barreras operativas significativas para sistemas de \"caja negra\" (black box).\n",
    "\n",
    "Impacto Operacional: El responsable del tratamiento no puede basarse exclusivamente en el algoritmo sin ofrecer vías de recurso. La obligación de proporcionar una \"explicación motivada\" y entregar los \"criterios de valoración\"  obliga a la empresa a tener la capacidad técnica de explicar la lógica del algoritmo (explicabilidad de la IA).\n",
    "\n",
    "Intervención Humana y Supervisión: La disposición obliga al responsable a proveer intervención humana a través del derecho de impugnación y presentación de observaciones. Si un usuario impugna una decisión automatizada, el responsable debe tener un proceso (humano) para revisar esa decisión, ya que el sistema automatizado por sí solo no puede \"recibir observaciones\" ni \"explicar motivadamente\" fuera de su programación. Además, el derecho a no ser objeto de estas decisiones implica que, si no se cumplen las excepciones (como el consentimiento explícito o la necesidad contractual), el responsable debe ofrecer una alternativa de evaluación no automatizada o híbrida.\n",
    "\n",
    "Referencia: Capítulo III (Derechos), Artículo 20.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b0cd22",
   "metadata": {},
   "source": [
    "### Under what conditions is the international transfer of personal data restricted by the LOPDP?   \n",
    "\n",
    "La transferencia internacional de datos personales está restringida y condicionada bajo el principio general de que solo se pueden transferir datos a destinos que garanticen un nivel de protección adecuado. Las condiciones son:\n",
    "\n",
    "- Nivel de Protección Adecuado: Se permite si el país u organización de destino ha sido declarado como de \"nivel adecuado de protección\" por la Autoridad de Protección de Datos Personales.\n",
    "- Garantías Adecuadas: Si no hay declaración de nivel adecuado, se puede transferir si el responsable ofrece garantías adecuadas (como instrumentos jurídicos vinculantes) que aseguren el cumplimiento de principios y derechos al menos al estándar ecuatoriano.\n",
    "- Normas Corporativas Vinculantes: Se permite entre grupos empresariales que hayan adoptado normas aprobadas por la Autoridad.\n",
    "- Autorización Expresa: Para casos no contemplados anteriormente, se requiere la autorización de la Autoridad de Protección de Datos.\n",
    "\n",
    "Excepciones (Art. 60): Se permiten transferencias sin lo anterior solo en casos puntuales como: cumplimiento de competencias institucionales, consentimiento explícito del titular (informado de los riesgos), necesidad contractual, interés público, operaciones bancarias/bursátiles, o protección de intereses vitales .\n",
    "\n",
    "Referencia: Capítulo IX (Transferencia o Comunicación Internacional de Datos Personales), Artículos 56, 57, 58, 59 y 60."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46baa865",
   "metadata": {},
   "source": [
    "### Explain the role of the Data Protection Authority (DPA) regarding international data transfers. How does this requirement create operational friction or regulatory compliance barriers for a multinational AI company that typically relies on centralized cloud infrastructure outside of Ecuador?   \n",
    "\n",
    "La Autoridad de Protección de Datos Personales (APD) actúa como un ente de control independiente que regula el flujo transfronterizo de información, con la potestad exclusiva de determinar mediante resolución qué países ofrecen un \"nivel adecuado de protección\" y de autorizar las transferencias a aquellos que no lo tienen. Su rol es actuar como un \"filtro\" obligatorio, exigiendo que cualquier transferencia internacional sea registrada previamente en el Registro Nacional de Protección de Datos Personales y cumpla con garantías jurídicas específicas antes de que los datos salgan del país.\n",
    "\n",
    "Sus funciones incluyen:\n",
    "- Calificar y declarar qué países u organizaciones tienen un nivel adecuado de protección mediante resolución motivada.\n",
    "- Autorizar transferencias internacionales que no caigan bajo los supuestos de nivel adecuado o garantías estándar.\n",
    "- Definir formatos y procedimientos para las normas corporativas vinculantes.\n",
    "- Realizar un control continuo y emitir resoluciones de \"no adecuación\" si un país deja de cumplir los estándares.\n",
    "\n",
    "Estos requisitos crean una fricción operativa significativa para las empresas multinacionales de IA, ya que impide el uso fluido de infraestructuras en la nube centralizadas o distribuidas si los servidores residen en jurisdicciones no homologadas por la APD. La necesidad de obtener autorizaciones administrativas previas y registrar los flujos de datos ex ante obliga a estas empresas a detener la automatización dinámica de sus redes para cumplir con procesos burocráticos locales, enfrentando además el riesgo de que la Autoridad emita resoluciones de \"no adecuación\" que bloqueen sus operaciones.\n",
    "\n",
    "Esto crea una barrera de cumplimiento considerable:\n",
    "- Incertidumbre de la \"Lista Blanca\": Si los servidores de la nube están en un país que la Autoridad ecuatoriana aún no ha calificado como \"adecuado\" (Art. 56), la transferencia está técnicamente bloqueada por defecto.\n",
    "- Cuello de Botella Burocrático: Si el país no es adecuado, la empresa debe solicitar una autorización específica a la Autoridad (Art. 59), lo cual implica presentar documentación y esperar una resolución administrativa, ralentizando el despliegue de servicios.\n",
    "- Carga Administrativa: La necesidad de registrar las transferencias internacionales en el Registro Nacional  y la obligación de implementar cláusulas contractuales o normas corporativas vinculantes aprobadas añaden capas de complejidad legal y costos de gestión para flujos de datos que suelen ser dinámicos y automatizados en servicios de nube.\n",
    "\n",
    "Referencia: Capítulo IX, Artículos 56, 59, 61; y Capítulo XII (Autoridad de Protección de Datos Personales), Artículo 76 numeral 10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e16344d",
   "metadata": {},
   "source": [
    "## 2. Corporate Policy Scrutiny: The Data Repurposing Conflict\n",
    "\n",
    "Major generative AI companies frequently face scrutiny for collecting and repurposing user data (such as chat inputs) for model training, a practice that directly challenges the principles of purpose limitation and explicit consent in global privacy laws.   \n",
    "\n",
    "### Select two major generative AI providers (e.g., OpenAI, Meta, or Anthropic). Briefly summarize how each company differentiates the data usage practices between their Enterprise/API Services (for paying business clients) and their Consumer/Chatbot Services (for free public users) regarding model training.   \n",
    "\n",
    "\n",
    "### Analyze the public-facing policy for the consumer chat version of one of your selected companies. Identify the type of user input data (e.g., chat content, account info, technical data) that may be used for model training.   \n",
    "\n",
    "### Describe the practical process a user must follow to opt out of having their data used for training (e.g., submission of a form, navigation of settings, or use of a specific toggle).   \n",
    "\n",
    "### Critically evaluate: How does this opt-out mechanism conflict with the LOPDP’s mandate for prior, informed, and explicit consent for data processing?   \n",
    "\n",
    "### Legal Risk Scenarios: Research a recent legal challenge or public controversy where an AI company (e.g., Meta, LinkedIn, or Amazon) was accused of using previously collected user-generated content or biometric data for a new, secondary AI training purpose without proper consent. Briefly summarize the nature of the alleged violation (e.g., biometric privacy, repurposing of communication data).   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122af109",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Technical Risk Assessment and Mitigation\n",
    "\n",
    "AI systems, especially those processing sensitive data, require robust security and governance to prevent privacy harms and data access risks. This module focuses on threat modeling and risk management.\n",
    "\n",
    "### Choose one high-risk application and detail a specific scenario where it could lead to severe harm or unauthorized data access\n",
    "\n",
    "### Assume we deploy a new AI-driven predictive policing system deployed in a major Latin American city. Describe how historical bias present in the training data (e.g., police reporting practices)  could cause the system to disproportionately target and surveil marginalized communities , resulting in discriminatory legal effects (a violation of LOPDP’s principle of proportionality  and the right to object to automated decisions ).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c6179a",
   "metadata": {},
   "source": [
    "### Explain the security threat known as \"Model Memorization\" or \"Data Leakage\" in generative AI. If an AI chatbot (used internally by a hospital) accidentally memorizes and reveals unmasked patient health information (PHI) shared during a training prompt, what specific privacy right under the LOPDP would be violated?   \n",
    "\n",
    "La amenaza conocida como \"Memorización del Modelo\" o Model Memorization representa un fallo crítico de seguridad en la inteligencia artificial generativa, donde el sistema, en lugar de aprender patrones abstractos, retiene y reproduce textualmente fragmentos específicos de los datos con los que fue entrenado. En el contexto hospitalario, si un chatbot entrenado con historiales médicos reales llega a exponer información de salud no enmascarada (PHI) ante una consulta, se estaría materializando una violación directa al Principio de Confidencialidad estipulado en el literal g) del Artículo 10 de la Ley Orgánica de Protección de Datos Personales (LOPDP). Este principio exige que los datos personales se traten con estricto sigilo y prohíbe explícitamente su comunicación para fines distintos a los que motivaron su recolección original, un mandato que se quebranta cuando la IA revela información privada a terceros no autorizados.\n",
    "\n",
    "Desde la perspectiva de la clasificación de la información, este incidente constituye un tratamiento ilícito de datos sensibles. La LOPDP, en su Artículo 25 y Artículo 4 , categoriza los datos de salud como información sensible, cuyo tratamiento está prohibido por regla general en el Artículo 26, salvo excepciones muy específicas (como el consentimiento explícito o la protección de intereses vitales) que no aplican a una filtración accidental. Por tanto, la exposición de estos datos por parte del chatbot carece de base legal y vulnera la protección especial que la ley otorga a la intimidad de los pacientes.\n",
    "\n",
    "Finalmente, el incidente demuestra un incumplimiento de las normativas específicas para el manejo de información sanitaria. El Artículo 30 refuerza el deber de confidencialidad y seguridad para cualquier entidad que procese datos de salud, mientras que el Artículo 31  establece un requisito técnico fundamental: los datos relativos a la salud deben ser, siempre que sea posible, previamente anonimizados o seudonimizados para impedir la identificación de sus titulares. Al permitir que el modelo \"memorice\" y revele datos crudos (unmasked), el hospital habría fallado en aplicar estas medidas de seguridad obligatorias, resultando en una vulneración integral del derecho a la protección de datos personales garantizado por la ley.\n",
    "\n",
    "Referencia: Capítulo I, Artículo 4; Capítulo II, Artículo 10, literal g; Capítulo IV, Artículos 25, 26, 30 y 31."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
