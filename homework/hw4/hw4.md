# Information Security
# Homework 4

## 1. Foundational Research: Ecuadorian Data Sovereignty (LOPDP)

Ecuador’s Ley Orgánica de Protección de Datos Personales (LOPDP), enforced starting in July 2023 , establishes comprehensive individual rights over personal data. This module requires you to research the specific mandates of this law as they relate to automated decision-making and cross-border data management.   

### What are the three core principles (criterios mínimos) that govern all data processing activities under the LOPDP?   

### Locate the specific article (or section within an article) of the LOPDP that grants the data subject the right “to not be object of a decision based solely on automated valuations”. Explain the details and protections it provides.  

### In the context of an AI-driven system (e.g., hiring or loan approval), explain the operational impact of this right. How does this LOPDP provision compel a data controller to provide human intervention or oversight?   

### Under what conditions is the international transfer of personal data restricted by the LOPDP?   

### Explain the role of the Data Protection Authority (DPA) regarding international data transfers. How does this requirement create operational friction or regulatory compliance barriers for a multinational AI company that typically relies on centralized cloud infrastructure outside of Ecuador?   

## 2. Corporate Policy Scrutiny: The Data Repurposing Conflict

Major generative AI companies frequently face scrutiny for collecting and repurposing user data (such as chat inputs) for model training, a practice that directly challenges the principles of purpose limitation and explicit consent in global privacy laws.   

### Select two major generative AI providers (e.g., OpenAI, Meta, or Anthropic). Briefly summarize how each company differentiates the data usage practices between their Enterprise/API Services (for paying business clients) and their Consumer/Chatbot Services (for free public users) regarding model training.   


### Analyze the public-facing policy for the consumer chat version of one of your selected companies. Identify the type of user input data (e.g., chat content, account info, technical data) that may be used for model training.   

### Describe the practical process a user must follow to opt out of having their data used for training (e.g., submission of a form, navigation of settings, or use of a specific toggle).   

### Critically evaluate: How does this opt-out mechanism conflict with the LOPDP’s mandate for prior, informed, and explicit consent for data processing?   

### Legal Risk Scenarios: Research a recent legal challenge or public controversy where an AI company (e.g., Meta, LinkedIn, or Amazon) was accused of using previously collected user-generated content or biometric data for a new, secondary AI training purpose without proper consent. Briefly summarize the nature of the alleged violation (e.g., biometric privacy, repurposing of communication data).   

## 3. Technical Risk Assessment and Mitigation

AI systems, especially those processing sensitive data, require robust security and governance to prevent privacy harms and data access risks. This module focuses on threat modeling and risk management.

### Choose one high-risk application and detail a specific scenario where it could lead to severe harm or unauthorized data access

### Assume we deploy a new AI-driven predictive policing system deployed in a major Latin American city. Describe how historical bias present in the training data (e.g., police reporting practices)  could cause the system to disproportionately target and surveil marginalized communities , resulting in discriminatory legal effects (a violation of LOPDP’s principle of proportionality  and the right to object to automated decisions ).   

### Explain the security threat known as "Model Memorization" or "Data Leakage" in generative AI. If an AI chatbot (used internally by a hospital) accidentally memorizes and reveals unmasked patient health information (PHI) shared during a training prompt, what specific privacy right under the LOPDP would be violated?   
