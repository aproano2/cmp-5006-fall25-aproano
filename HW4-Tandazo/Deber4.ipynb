{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e92c063",
   "metadata": {},
   "source": [
    "# Foundational Research: Ecuadorian Data Sovereignty (LOPDP)\n",
    "\n",
    "## What are the three core principles that govern all data processing activities under the LOPDP?\n",
    "\n",
    "En el artículo, los tres principios fundamentales que gobiernan todas las actividades de tratamiento de datos personales son los siguientes:\n",
    "\n",
    "### Principio de juridicidad\n",
    "\n",
    "De acuerdo con el Artículo 10, literal (a), todos los datos personales deben ser tratados bajo un estricto apego a la Constitución de la República del Ecuador, a los instrumentos internacionales ratificados por el Estado, a la ley, a su Reglamento y a la demás normativa aplicable.\n",
    "\n",
    "Este principio exige que todo tratamiento de los datos personales, incluidos los sistemas automatizados y, por consiguiente, basados en IA, cuenten con una base jurídica válida, como el consentimiento de los titulares, una obligación legal o un interés legítimo.\n",
    "\n",
    "Desde la perspectiva de la seguridad de la información, este principio impone la incorporación de mecanismos de cumplimiento normativo desde el diseño de los sistemas.\n",
    "\n",
    "### Principio de necesidad\n",
    "\n",
    "El principio de proporcionalidad y necesidad es reconocido como uno de los criterios mínimos en el Artículo 2, literales (e) y (f), y se desarrolla en el Artículo 10, literales (e) y (f).\n",
    "\n",
    "En este principio se establece que los datos personales deben ser pertinentes, adecuados, estrictamente necesarios y no excesivos en relación con la finalidad perseguida.\n",
    "\n",
    "En sistemas informáticos y automatizados, este principio obliga a aplicar prácticas de minimización de datos, reduciendo la superficie de ataque y mitigando los riesgos asociados a eventuales vulneraciones de seguridad.\n",
    "\n",
    "### Principio de finalidad\n",
    "\n",
    "El Artículo 10, literal (d), consagra el principio de finalidad, conforme al cual los datos personales deben ser recolectados para fines determinados, explícitos y legítimos, y no pueden ser tratados posteriormente para finalidades incompatibles con aquellas para las que fueron inicialmente obtenidos.\n",
    "\n",
    "Este principio resulta esencial en el control de sistemas de decisión automatizada, debido a que limita el uso secundario no autorizado de la información.\n",
    "\n",
    "Desde el enfoque de seguridad de la información, se exige la implementación de controles de acceso, segmentación de bases de datos y mecanismos de auditoría que garanticen el uso adecuado de los datos personales.\n",
    "\n",
    "---\n",
    "\n",
    "## Locate the specific article of the LOPDP that grants the data subject the right “to not be object of a decision based solely on automated valuations”\n",
    "\n",
    "El derecho de los titulares a no ser objeto de decisiones basadas únicamente en valoraciones automatizadas se encuentra en el **Artículo 20**, Capítulo III, relativo a los derechos de los titulares.\n",
    "\n",
    "> Cada titular tiene derecho a no ser sometido a una decisión basada *única o parcialmente* en valoraciones producto de procesos automatizados, incluida la elaboración de perfiles, cuando dichas decisiones produzcan efectos jurídicos o atenten contra sus derechos y libertades fundamentales.\n",
    "\n",
    "Este derecho incluye las siguientes garantías:\n",
    "\n",
    "- Solicitar una explicación motivada de la decisión.\n",
    "- Presentar observaciones respecto a la decisión automatizada.\n",
    "- Solicitar información sobre los criterios de valoración utilizados.\n",
    "- Conocer los tipos de datos empleados y su fuente.\n",
    "- Impugnar la decisión ante el responsable o encargado del tratamiento.\n",
    "\n",
    "El Artículo 20 también establece excepciones, por ejemplo, cuando la decisión sea necesaria para la ejecución de un contrato, esté autorizada por una norma jurídica u orden judicial, se base en el consentimiento explícito del titular o no conlleve impactos graves o riesgos verificables.\n",
    "\n",
    "---\n",
    "\n",
    "## Operational impact of Article 20 in AI-driven decision-making systems\n",
    "\n",
    "### Limitación a decisiones totalmente automatizadas\n",
    "\n",
    "El Artículo 20 prohíbe flujos de decisión completamente autónomos en contextos de alto impacto, como:\n",
    "\n",
    "- Rechazo automatizado de postulantes a un empleo.\n",
    "- Denegación automatizada de créditos o préstamos.\n",
    "- Sistemas de puntuación automatizada con efectos contractuales o económicos.\n",
    "\n",
    "### Intervención humana obligatoria\n",
    "\n",
    "El responsable debe incorporar intervención humana efectiva para garantizar:\n",
    "\n",
    "1. Explicación motivada de la decisión.\n",
    "2. Presentación de observaciones.\n",
    "3. Información sobre criterios de valoración.\n",
    "4. Impugnación de la decisión.\n",
    "\n",
    "Esto implica que un decisor humano debe poder revisar, modificar o revocar la decisión algorítmica.\n",
    "\n",
    "### Impacto en la arquitectura y gobernanza\n",
    "\n",
    "Los sistemas deben incorporar:\n",
    "\n",
    "- Arquitecturas *human-in-the-loop* o *human-on-the-loop*.\n",
    "- Registros de auditoría y trazabilidad.\n",
    "- Mecanismos de explicación del modelo.\n",
    "- Procedimientos de impugnación dentro de plazos legales.\n",
    "\n",
    "---\n",
    "\n",
    "## Under what conditions is the international transfer of personal data restricted by the LOPDP?\n",
    "\n",
    "La LOPDP permite la transferencia internacional, pero bajo condiciones estrictas.\n",
    "\n",
    "### Aplicación extraterritorial\n",
    "\n",
    "Según el Artículo 3, la ley se aplica cuando:\n",
    "\n",
    "- Se tratan datos de titulares que residen en Ecuador.\n",
    "- El tratamiento se relaciona con la oferta de bienes o servicios a dichos titulares.\n",
    "\n",
    "### Requisitos de licitud y consentimiento\n",
    "\n",
    "La transferencia se restringe si:\n",
    "\n",
    "- No existe una base jurídica válida.\n",
    "- No hay consentimiento informado cuando es requerido.\n",
    "- La finalidad no es compatible con la original.\n",
    "\n",
    "### Transferencias a terceros en el extranjero\n",
    "\n",
    "Está restringida cuando:\n",
    "\n",
    "- No existe contrato que limite el tratamiento.\n",
    "- El destinatario reutiliza los datos para fines propios.\n",
    "- No hay mecanismos de eliminación o devolución de los datos.\n",
    "\n",
    "### Datos sensibles\n",
    "\n",
    "La transferencia internacional de datos sensibles solo es lícita cuando:\n",
    "\n",
    "- Existe consentimiento explícito.\n",
    "- Hay interés público esencial.\n",
    "- Se aplican salvaguardas reforzadas.\n",
    "\n",
    "---\n",
    "\n",
    "## Role of the Data Protection Authority (DPA)\n",
    "\n",
    "La DPA supervisa las transferencias internacionales y puede exigir pruebas de base jurídica válida, conservación de la finalidad y garantías adecuadas.\n",
    "\n",
    "Para empresas multinacionales con infraestructura cloud fuera del Ecuador, esto genera fricciones operativas, como segmentación geográfica de datos y mayores costos de cumplimiento.\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "## Corporate Policy Scrutiny: The Data Repurposing Conflict\n",
    "\n",
    "### Select two major generative AI providers (e.g., OpenAI, Meta, or Anthropic)\n",
    "\n",
    "Briefly summarize how each company differentiates the data usage practices between their Enterprise/API Services (for paying business clients) and their Consumer/Chatbot Services (for free public users) regarding model training.\n",
    "\n",
    "Para analizar este conflictos de datos y las de limitación de finalidad y consentimiento explícito, se seleccionaron dos servicios que han incursionado inteligencia artificial generativa: **OpenAI** y **Meta**. Ambos adoptan modelos de negocio diferentes respecto al uso de datos personales para el entrenamiento de modelos, lo que permitirá contrastar sus enfoques frente a la LOPDP.\n",
    "\n",
    "#### OpenAI: diferenciación explícita entre servicios empresariales y de consumo\n",
    "\n",
    "OpenAI establece una separación entre sus servicios empresariales y su servicio de consumo.\n",
    "\n",
    "En el caso de **ChatGPT y los servicios API**, la política corporativa indica que los datos proporcionados por clientes de pago **no se utilizan para entrenar modelos** por defecto. Dichos datos permanecen bajo control del cliente, con garantías contractuales de confidencialidad y limitación de finalidad.\n",
    "\n",
    "En contraste, el servicio de **ChatGPT gratuito** puede utilizar el contenido de las conversaciones, junto con información de cuenta y datos técnicos, para mejorar y entrenar sus modelos, salvo que el usuario ejerza un mecanismo de exclusión voluntaria (*opt-out*), reflejando un modelo en el que la protección de datos depende del tipo de usuario.\n",
    "\n",
    "#### Meta: integración de IA generativa en servicios de consumo\n",
    "\n",
    "Meta no ofrece una separación clara entre servicios de inteligencia artificial empresariales y servicios de consumo, ya que sus capacidades de IA generativa están integradas en Facebook, Instagram, Messenger y WhatsApp, nutriéndose principalmente del contenido generado por usuarios.\n",
    "\n",
    "Las políticas indican que la información compartida por los usuarios —como texto, imágenes, audio, video y metadatos— puede ser utilizada para desarrollar, mejorar y entrenar sistemas de inteligencia artificial y aprendizaje automático. Esta práctica se enmarca en finalidades amplias de investigación, mejora de productos y desarrollo de nuevas funcionalidades, sin una distinción explícita entre datos para la prestación del servicio y datos reutilizados para entrenamiento de modelos.\n",
    "\n",
    "#### Comparación y relevancia jurídica\n",
    "\n",
    "OpenAI adopta un modelo de **segmentación**, donde el uso de datos para entrenamiento depende del tipo de servicio contratado, mientras que Meta sigue un modelo de **integración total**, en el cual los datos de usuarios de servicios gratuitos alimentan de forma generalizada el desarrollo de sistemas de IA.\n",
    "\n",
    "Desde la perspectiva de la LOPDP, ambos modelos presentan riesgos, pero el enfoque de Meta plantea un conflicto estructural más profundo con los principios de finalidad y consentimiento explícito, al basar el entrenamiento de IA en datos recolectados originalmente para fines sociales.\n",
    "\n",
    "| **Criterio** | **OpenAI** | **Meta** |\n",
    "|-------------|-----------|----------|\n",
    "| Tipo de servicios | Servicios diferenciados (Enterprise/API vs. Consumer) | Ecosistema integrado (redes sociales + Meta AI) |\n",
    "| Usuarios principales | Empresas (servicios de pago) y público general (servicio gratuito) | Principalmente usuarios gratuitos |\n",
    "| Uso de datos para entrenamiento | Enterprise/API: no se utilizan por defecto<br>Consumer: sí, salvo *opt-out* | Uso amplio de contenido generado por usuarios |\n",
    "| Separación entre consumo y entrenamiento | Clara y explícita | Débil o inexistente |\n",
    "| Modelo de consentimiento | Exclusión voluntaria posterior (*opt-out*) | Configuración posterior y control fragmentado |\n",
    "| Riesgo frente a la LOPDP | Alto en servicios de consumo | Alto y estructural |\n",
    "\n",
    "---\n",
    "\n",
    "### Analyze the public-facing policy for the consumer chat version of one selected company\n",
    "\n",
    "Para este análisis, se examinó la política de privacidad del servicio de chat de consumo de **OpenAI**, en tanto se trata de un servicio gratuito orientado al público general y representa un caso casi paradigmático de reutilización de datos personales para el entrenamiento.\n",
    "\n",
    "De acuerdo con la política de OpenAI, el servicio de consumo recopila y puede utilizar diversas categorías de datos personales proporcionados directa o indirectamente por los usuarios:\n",
    "\n",
    "- **Contenido del usuario**: mensajes de conversación, archivos, imágenes, audio y otros contenidos cargados.\n",
    "- **Información de la cuenta**: nombre, información de contacto, credenciales de acceso, fecha de nacimiento, información de pago e historial de transacciones.\n",
    "- **Información de comunicación**: datos proporcionados al comunicarse con OpenAI por correo, redes sociales u otros canales.\n",
    "- **Información técnica**: dirección IP, navegador, fechas y horas de acceso, zona horaria, país, tipo de dispositivo, sistema operativo, identificadores del dispositivo, cookies y datos de interacción.\n",
    "- **Información de ubicación**: ubicación aproximada inferida por IP y ubicación precisa proporcionada voluntariamente.\n",
    "\n",
    "La política establece que OpenAI puede usar el **contenido de usuarios del servicio de consumo** para *mejorar y desarrollar sus servicios*, incluyendo el **entrenamiento de los modelos que impulsan ChatGPT**, salvo que el usuario ejerza un mecanismo de exclusión voluntaria.\n",
    "\n",
    "En contraste, los contenidos procesados para clientes **Business o API** no se rigen por esta política y **no se utilizan para entrenamiento**.\n",
    "\n",
    "---\n",
    "\n",
    "### Describe the practical opt-out process\n",
    "\n",
    "Los mecanismos de exclusión del uso de datos presentan diferencias relevantes entre OpenAI y Meta.\n",
    "\n",
    "#### OpenAI (ChatGPT)\n",
    "\n",
    "El usuario puede ejercer un *opt-out* accediendo a la configuración de su cuenta o presentando una solicitud expresa a través del portal de privacidad de OpenAI o por correo electrónico. El entrenamiento opera **por defecto**, salvo oposición expresa del titular.\n",
    "\n",
    "#### Meta\n",
    "\n",
    "Meta no ofrece un mecanismo unificado y específico de *opt-out* para el entrenamiento de IA. El control se limita a herramientas generales de privacidad y al ejercicio de derechos de acceso o eliminación, sin exclusión directa del entrenamiento de modelos.\n",
    "\n",
    "---\n",
    "\n",
    "### Critical evaluation: conflict with the LOPDP\n",
    "\n",
    "Los mecanismos de *opt-out* entran en conflicto con el consentimiento **previo, informado y específico** exigido por la LOPDP.\n",
    "\n",
    "El tratamiento inicia por defecto, lo cual contradice el carácter **previo** del consentimiento. Además, no es **específico** cuando requiere acciones adicionales complejas, ni plenamente **informado** debido a políticas amplias y técnicas que no distinguen claramente la finalidad principal del servicio del entrenamiento de modelos.\n",
    "\n",
    "Desde el principio de **limitación de finalidad**, el entrenamiento constituye una finalidad secundaria que no puede legitimarse mediante oposición posterior.\n",
    "\n",
    "---\n",
    "\n",
    "### Legal Risk Scenario\n",
    "\n",
    "Un caso relevante y documentado involucra a Meta Platforms, Inc. y la recolección y uso no autorizado de datos biométricos de los usuarios de sus plataformas, especialmente relacionados con tecnologías de reconocimiento facial.\n",
    "\n",
    "En febrero de 2022, se demandó a Meta en Texas por capturar y utilizar datos biométricos personales—incluyendo registros de geometría facial—de millones de residentes sin el consentimiento informado requerido por la ley estatal.\n",
    "\n",
    "---\n",
    "\n",
    "## Technical Risk Assessment and Mitigation\n",
    "\n",
    "Los sistemas de IA presentan riesgos técnicos que pueden afectar gravemente los derechos de los titulares.\n",
    "\n",
    "### High-Risk Application: Predictive Policing\n",
    "\n",
    "Los sistemas de **policía predictiva** pueden reforzar sesgos históricos, generando vigilancia desproporcionada y efectos discriminatorios. Esto vulnera el principio de proporcionalidad y el **Artículo 20 de la LOPDP**.\n",
    "\n",
    "### Technical Security Risk: Model Memorization and Data Leakage\n",
    "\n",
    "El *model memorization* ocurre cuando un modelo reproduce información personal aprendida durante el entrenamiento. En contextos como hospitales, esto puede derivar en divulgación no autorizada de **datos de salud**, considerados datos sensibles.\n",
    "\n",
    "### Relevancia para la gobernanza y mitigación\n",
    "\n",
    "Estos riesgos obligan a implementar medidas desde el diseño del sistema:\n",
    "\n",
    "- Evaluación de sesgos\n",
    "- Supervisión humana efectiva\n",
    "- Minimización de datos\n",
    "- Controles de acceso estrictos\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "# Bibliografía\n",
    "\n",
    "- **Ley Orgánica de Protección de Datos Personales (LOPDP)**, CORDICOM, 2021  \n",
    "  https://www.consejodecomunicacion.gob.ec/wp-content/uploads/downloads/2021/07/lotaip/Ley%20Org%C3%A1nica%20de%20Protecci%C3%B3n%20de%20Datos%20Personales.pdf\n",
    "\n",
    "- **Política de Privacidad — OpenAI (ChatGPT)**  \n",
    "  https://openai.com/es-419/policies/row-privacy-policy/\n",
    "\n",
    "- **Política de Privacidad — Meta**  \n",
    "  https://www.facebook.com/privacy/policy/\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
